#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@File       : batch_analyze.py
@Description: æ‰¹é‡é’±åŒ…åˆ†æå·¥å…· V2 (è¶…ä¸¥æ ¼ç‰ˆ)
              - æ‰¹é‡åˆ†æå¤šä¸ªé’±åŒ…åœ°å€
              - è‡ªåŠ¨é»‘åå•è¿‡æ»¤ä½è´¨é‡é’±åŒ…
              - å¯¼å‡º Excel æŠ¥å‘Šï¼ˆåŒ…å«è¯¦ç»†è¯„åˆ†å’Œå®šä½ï¼‰
              - æ”¹è¿›é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
@Author     : Auto-generated
@Date       : 2026-02-02
"""
import asyncio
import logging
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

import aiohttp
import pandas as pd
from tqdm.asyncio import tqdm

from tools.SMV2.key_list import HELIUS_KEY_LIST, JUPITER_KEY_LIST

# ç¡®ä¿èƒ½æ‰¾åˆ° analyze_wallet æ¨¡å—
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

try:
    from analyze_wallet import WalletAnalyzerV2, WalletScorerV2
except ImportError:
    print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° analyze_wallet æ¨¡å—")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# === âš™ï¸ é…ç½®å¸¸é‡ ===
TOOLS_DIR = Path(__file__).parent.parent
TRASH_FILE = str(TOOLS_DIR / "wallets_trash.txt")
WALLETS_FILE = str(TOOLS_DIR / "wallets_check.txt")
RESULTS_DIR = str(Path(__file__).parent / "results")
CONCURRENT_LIMIT = 5  # å¹¶å‘é™åˆ¶
DUST_THRESHOLD = 0.01  # ç²‰å°˜é˜ˆå€¼ï¼šæœªå®ç°æ”¶ç›Šä½äºæ­¤å€¼çš„ä»£å¸è§†ä¸ºç²‰å°˜


class APIKeyManager:
    """
    API Key ç®¡ç†å™¨ï¼šè´Ÿè´£ç®¡ç†å¤šä¸ª API Keyï¼Œå…è®¸å¹¶è¡Œä½¿ç”¨ï¼Œä½†åŒä¸€ Key é—´éš”è‡³å°‘1ç§’
    
    èŒè´£ï¼š
    - ä¸ºæ¯ä¸ª Key åˆ›å»ºç‹¬ç«‹çš„é”ï¼Œå…è®¸ä¸åŒ Key å¹¶è¡Œä½¿ç”¨
    - è·Ÿè¸ªæ¯ä¸ª Key çš„æœ€åè°ƒç”¨æ—¶é—´
    - ç¡®ä¿åŒä¸€ Key çš„è°ƒç”¨é—´éš”è‡³å°‘1ç§’
    """

    def __init__(self, key_list: List[str], api_name: str = "API"):
        """
        åˆå§‹åŒ– API Key ç®¡ç†å™¨
        
        Args:
            key_list: API Key åˆ—è¡¨
            api_name: API åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        if not key_list:
            raise ValueError(f"{api_name} Key åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        self.key_list = [k for k in key_list if k and k.strip()]  # è¿‡æ»¤ç©ºå€¼
        if not self.key_list:
            raise ValueError(f"{api_name} Key åˆ—è¡¨ä¸­æ²¡æœ‰æœ‰æ•ˆçš„ Key")
        self.api_name = api_name
        # ä¸ºæ¯ä¸ª Key åˆ›å»ºç‹¬ç«‹çš„é”å’Œè°ƒç”¨æ—¶é—´è·Ÿè¸ª
        self.key_locks: Dict[str, asyncio.Lock] = {key: asyncio.Lock() for key in self.key_list}
        self.last_call_times: Dict[str, float] = {}  # {key: last_call_timestamp}
        self.current_index = 0
        self._index_lock = asyncio.Lock()  # ç”¨äºè½®è¯¢é€‰æ‹©Keyçš„é”
        logger.info(f"åˆå§‹åŒ– {api_name} Key ç®¡ç†å™¨: {len(self.key_list)} ä¸ª Keysï¼ˆæ”¯æŒå¹¶è¡Œï¼‰")

    async def get_key_and_lock(self) -> Tuple[str, asyncio.Lock]:
        """
        è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Key å’Œå¯¹åº”çš„é”ï¼ˆç¡®ä¿é—´éš”è‡³å°‘1ç§’ï¼‰
        
        Returns:
            (key, lock): å¯ç”¨çš„ API Key å’Œå¯¹åº”çš„é”
        """
        import time
        async with self._index_lock:
            current_time = time.time()

            # å°è¯•æ‰¾åˆ°å¯ç”¨çš„ Keyï¼ˆè·ç¦»ä¸Šæ¬¡è°ƒç”¨è‡³å°‘1ç§’ï¼‰
            for _ in range(len(self.key_list)):
                key = self.key_list[self.current_index]
                last_call = self.last_call_times.get(key, 0)
                elapsed = current_time - last_call

                if elapsed >= 1.0:
                    # è¿™ä¸ª Key å¯ç”¨ï¼Œæ›´æ–°è°ƒç”¨æ—¶é—´å¹¶è¿”å›
                    self.last_call_times[key] = current_time
                    self.current_index = (self.current_index + 1) % len(self.key_list)
                    return key, self.key_locks[key]

                # è¿™ä¸ª Key ä¸å¯ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                self.current_index = (self.current_index + 1) % len(self.key_list)

            # å¦‚æœæ‰€æœ‰ Key éƒ½ä¸å¯ç”¨ï¼Œç­‰å¾…æœ€çŸ­çš„æ—¶é—´
            if self.last_call_times:
                wait_times = [1.0 - (current_time - last_call)
                              for last_call in self.last_call_times.values()
                              if (current_time - last_call) < 1.0]
                if wait_times:
                    min_wait = min(wait_times)
                    if min_wait > 0:
                        await asyncio.sleep(min_wait)
                        current_time = time.time()

            # å†æ¬¡å°è¯•è·å– Keyï¼ˆæ­¤æ—¶åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªå¯ç”¨ï¼‰
            key = self.key_list[self.current_index]
            self.last_call_times[key] = current_time
            self.current_index = (self.current_index + 1) % len(self.key_list)
            return key, self.key_locks[key]


def is_valid_solana_address(address: str) -> bool:
    """
    éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ Solana é’±åŒ…åœ°å€
    
    Args:
        address: å¾…éªŒè¯çš„åœ°å€å­—ç¬¦ä¸²
        
    Returns:
        æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ Solana åœ°å€
    """
    if not address or not isinstance(address, str):
        return False

    # Solana åœ°å€é•¿åº¦é€šå¸¸åœ¨ 32-44 ä½ï¼Œä½¿ç”¨ Base58 å­—ç¬¦é›†
    if not (32 <= len(address) <= 44):
        return False

    # Base58 å­—ç¬¦é›†ï¼šä¸åŒ…å« 0, O, I, l
    if not re.match(r'^[1-9A-HJ-NP-Za-km-z]+$', address):
        return False

    # æ’é™¤ç³»ç»Ÿåœ°å€
    if address == "So11111111111111111111111111111111111111111":
        return False

    return True


class WalletListSaver:
    """
    é’±åŒ…åˆ—è¡¨ä¿å­˜å™¨ï¼šè´Ÿè´£å°†æœ‰æ•ˆçš„é’±åŒ…åœ°å€ä¿å­˜å›æ–‡ä»¶
    """

    @staticmethod
    def save_valid_addresses(
            addresses: List[str],
            wallets_file: str = WALLETS_FILE
    ) -> bool:
        """
        ä¿å­˜æœ‰æ•ˆçš„é’±åŒ…åœ°å€åˆ°æ–‡ä»¶ï¼ˆå»é‡ã€éªŒè¯æ ¼å¼ï¼‰
        
        Args:
            addresses: é’±åŒ…åœ°å€åˆ—è¡¨
            wallets_file: é’±åŒ…åˆ—è¡¨æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        if not addresses:
            logger.warning("æ²¡æœ‰åœ°å€éœ€è¦ä¿å­˜")
            return False

        try:
            # éªŒè¯å¹¶å»é‡
            valid_addresses = set()
            for addr in addresses:
                addr = addr.strip()
                if addr and is_valid_solana_address(addr):
                    valid_addresses.add(addr)

            if not valid_addresses:
                logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„é’±åŒ…åœ°å€éœ€è¦ä¿å­˜")
                return False

            # æ’åºå¹¶ä¿å­˜
            sorted_addresses = sorted(list(valid_addresses))

            with open(wallets_file, 'w', encoding='utf-8') as f:
                for addr in sorted_addresses:
                    f.write(f"{addr}\n")

            logger.info(f"å·²ä¿å­˜ {len(sorted_addresses)} ä¸ªæœ‰æ•ˆé’±åŒ…åœ°å€åˆ° {wallets_file}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é’±åŒ…åœ°å€å¤±è´¥: {e}")
            return False


class TrashListManager:
    """
    é»‘åå•ç®¡ç†å™¨ï¼šè´Ÿè´£ç®¡ç†ä½è´¨é‡é’±åŒ…é»‘åå•
    """

    def __init__(self, trash_file: str = TRASH_FILE):
        """
        åˆå§‹åŒ–é»‘åå•ç®¡ç†å™¨
        
        Args:
            trash_file: é»‘åå•æ–‡ä»¶è·¯å¾„
        """
        self.trash_file = trash_file
        self._trash_set: Optional[Set[str]] = None

    def load(self) -> Set[str]:
        """
        åŠ è½½é»‘åå•
        
        Returns:
            é»‘åå•åœ°å€é›†åˆ
        """
        if self._trash_set is not None:
            return self._trash_set

        if not os.path.exists(self.trash_file):
            self._trash_set = set()
            return self._trash_set

        try:
            with open(self.trash_file, 'r', encoding='utf-8') as f:
                self._trash_set = {line.strip() for line in f if line.strip()}
            logger.info(f"åŠ è½½é»‘åå•: {len(self._trash_set)} ä¸ªåœ°å€")
        except Exception as e:
            logger.error(f"åŠ è½½é»‘åå•å¤±è´¥: {e}")
            self._trash_set = set()

        return self._trash_set

    def add(self, address: str) -> bool:
        """
        æ·»åŠ åœ°å€åˆ°é»‘åå•
        
        Args:
            address: é’±åŒ…åœ°å€
            
        Returns:
            æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            with open(self.trash_file, 'a', encoding='utf-8') as f:
                f.write(f"{address}\n")

            if self._trash_set is not None:
                self._trash_set.add(address)

            logger.debug(f"å·²æ·»åŠ åœ°å€åˆ°é»‘åå•: {address[:6]}...")
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ é»‘åå•å¤±è´¥: {e}")
            return False

    def contains(self, address: str) -> bool:
        """
        æ£€æŸ¥åœ°å€æ˜¯å¦åœ¨é»‘åå•ä¸­
        
        Args:
            address: é’±åŒ…åœ°å€
            
        Returns:
            æ˜¯å¦åœ¨é»‘åå•ä¸­
        """
        if self._trash_set is None:
            self.load()
        return address in (self._trash_set or set())


class WalletListLoader:
    """
    é’±åŒ…åˆ—è¡¨åŠ è½½å™¨ï¼šè´Ÿè´£ä»æ–‡ä»¶åŠ è½½é’±åŒ…åœ°å€åˆ—è¡¨
    """

    @staticmethod
    def load(wallets_file: str = WALLETS_FILE) -> List[str]:
        """
        ä»æ–‡ä»¶åŠ è½½é’±åŒ…åœ°å€åˆ—è¡¨
        
        Args:
            wallets_file: é’±åŒ…åˆ—è¡¨æ–‡ä»¶è·¯å¾„
            
        Returns:
            é’±åŒ…åœ°å€åˆ—è¡¨
        """
        if not os.path.exists(wallets_file):
            logger.error(f"æ‰¾ä¸åˆ°é’±åŒ…åˆ—è¡¨æ–‡ä»¶: {wallets_file}")
            return []

        try:
            with open(wallets_file, 'r', encoding='utf-8') as f:
                addresses = [
                    line.strip()
                    for line in f
                    if line.strip() and not line.startswith("#")
                ]
                addresses = list(set(addresses))
            logger.info(f"ä» {wallets_file} åŠ è½½äº† {len(addresses)} ä¸ªåœ°å€")
            return addresses
        except Exception as e:
            logger.error(f"åŠ è½½é’±åŒ…åˆ—è¡¨å¤±è´¥: {e}")
            return []


class BatchAnalyzerV2:
    """
    æ‰¹é‡åˆ†æå™¨ V2ï¼šè´Ÿè´£æ‰¹é‡åˆ†æå¤šä¸ªé’±åŒ…ï¼ˆè¶…ä¸¥æ ¼ç‰ˆï¼‰
    
    èŒè´£ï¼š
    - å¹¶å‘åˆ†æå¤šä¸ªé’±åŒ…ï¼ˆæ•°æ®å¤„ç†å¹¶å‘ï¼ŒAPIè°ƒç”¨ä¸²è¡Œï¼‰
    - è‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡é’±åŒ…ï¼ˆåƒåœ¾åœ°å€ï¼‰
    - ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š
    
    è®¾è®¡ï¼š
    - ä½¿ç”¨ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼
    - APIè°ƒç”¨ï¼ˆHelius/Jupiterï¼‰ä¸²è¡ŒåŒ–ï¼Œé¿å…å¹¶å‘è°ƒç”¨
    - æ•°æ®å¤„ç†ï¼ˆè§£æã€è¯„åˆ†è®¡ç®—ï¼‰å¯ä»¥å¹¶å‘
    """

    def __init__(
            self,
            analyzer: WalletAnalyzerV2,
            trash_manager: TrashListManager,
            helius_key_manager: APIKeyManager,
            jupiter_key_manager: APIKeyManager,
            concurrent_limit: int = CONCURRENT_LIMIT
    ):
        """
        åˆå§‹åŒ–æ‰¹é‡åˆ†æå™¨
        
        Args:
            analyzer: é’±åŒ…åˆ†æå™¨å®ä¾‹
            trash_manager: é»‘åå•ç®¡ç†å™¨å®ä¾‹
            helius_key_manager: Helius API Key ç®¡ç†å™¨
            jupiter_key_manager: Jupiter API Key ç®¡ç†å™¨
            concurrent_limit: æ•°æ®å¤„ç†å¹¶å‘é™åˆ¶ï¼ˆAPIè°ƒç”¨å§‹ç»ˆä¸²è¡Œï¼‰
        """
        self.analyzer = analyzer
        self.trash_manager = trash_manager
        self.helius_key_manager = helius_key_manager
        self.jupiter_key_manager = jupiter_key_manager
        self.concurrent_limit = concurrent_limit
        # æ•°æ®å¤„ç†å¹¶å‘æ§åˆ¶
        self.data_processing_semaphore = asyncio.Semaphore(concurrent_limit)
        # ç§»é™¤å…¨å±€api_lockï¼Œæ”¹ä¸ºæ¯ä¸ªKeyç‹¬ç«‹çš„é”ï¼ˆå…è®¸Nä¸ªKeyå¹¶è¡Œï¼ŒN=keyæ•°é‡ï¼‰

    async def analyze_one_wallet(
            self,
            session: aiohttp.ClientSession,
            address: str,
            pbar: tqdm,
            max_txs: int = 5000
    ) -> Optional[Dict]:
        """
        åˆ†æå•ä¸ªé’±åŒ…ï¼ˆç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼‰
        
        Args:
            session: aiohttp ä¼šè¯å¯¹è±¡
            address: é’±åŒ…åœ°å€
            pbar: è¿›åº¦æ¡å¯¹è±¡
            max_txs: æœ€å¤§äº¤æ˜“æ•°é‡
            
        Returns:
            åˆ†æç»“æœå­—å…¸ï¼Œå¦‚æœå¤±è´¥æˆ–åº”è¿‡æ»¤åˆ™è¿”å› None
        """
        try:
            # === é˜¶æ®µ1ï¼šAPIè°ƒç”¨ï¼ˆå…è®¸Nä¸ªKeyå¹¶è¡Œï¼ŒN=keyæ•°é‡ï¼Œä½†åŒä¸€Keyå†…éƒ¨ä¸²è¡Œï¼‰===
            # è·å–å¯ç”¨çš„Helius Keyå’Œå¯¹åº”çš„é”ï¼ˆç¡®ä¿åŒä¸€Keyé—´éš”1ç§’ï¼‰
            helius_key, helius_lock = await self.helius_key_manager.get_key_and_lock()
            async with helius_lock:
                # 1. æ‹‰å–äº¤æ˜“æ•°æ®ï¼ˆHelius APIï¼‰
                try:
                    txs = await self.analyzer.fetch_history_pagination(
                        session, address, max_txs, helius_api_key=helius_key
                    )
                except ValueError as e:
                    # API Key æœªé…ç½®ç­‰é…ç½®é”™è¯¯
                    logger.error(f"é…ç½®é”™è¯¯: {e}")
                    pbar.update(1)
                    return None
                except aiohttp.ClientError as e:
                    # ç½‘ç»œé”™è¯¯ï¼ˆè¿æ¥å¤±è´¥ã€è¶…æ—¶ç­‰ï¼‰
                    logger.warning(f"ç½‘ç»œé”™è¯¯è·å–é’±åŒ… {address[:8]}... äº¤æ˜“æ•°æ®: {e}")
                    pbar.update(1)
                    return None
                except Exception as e:
                    # å…¶ä»–æœªçŸ¥é”™è¯¯
                    logger.warning(f"è·å–é’±åŒ… {address[:8]}... äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
                    pbar.update(1)
                    return None

                # å¦‚æœè¿”å›ç©ºåˆ—è¡¨ï¼Œå¯èƒ½æ˜¯åœ°å€ä¸å­˜åœ¨ï¼ˆ404ï¼‰ï¼ŒåŠ å…¥é»‘åå•
                if txs == []:
                    logger.info(f"åœ°å€ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {address[:8]}...ï¼ŒåŠ å…¥é»‘åå•")
                    self.trash_manager.add(address)
                    pbar.update(1)
                    return None

                # ä¼˜åŒ–ï¼šå¦‚æœäº¤æ˜“æ•°é‡å¤ªå°‘ï¼ˆ<10ç¬”ï¼‰ï¼Œå¯èƒ½ä¸å€¼å¾—åˆ†æï¼Œæå‰é€€å‡º
                if not txs or len(txs) < 10:
                    pbar.update(1)
                    return None

            # 2. è§£æä»£å¸é¡¹ç›®ï¼ˆå†…éƒ¨ä¼šè°ƒç”¨ Jupiter APIï¼‰
            # æ³¨æ„ï¼šHeliuså’ŒJupiterä¹‹é—´ä¸éœ€è¦é—´éš”ï¼Œåªæœ‰åŒä¸€APIä¹‹é—´éœ€è¦é—´éš”
            # Jupiter API çš„ Key ä¼šåœ¨ PriceFetcher å†…éƒ¨é€šè¿‡ key_manager è·å–
            try:
                analysis_result = await self.analyzer.parse_token_projects(
                    session, txs, address, jupiter_key_manager=self.jupiter_key_manager
                )
            except Exception as e:
                logger.warning(f"è§£æé’±åŒ… {address[:8]}... ä»£å¸é¡¹ç›®å¤±è´¥: {e}")
                pbar.update(1)
                return None

            # ä¼˜åŒ–ï¼šå¦‚æœæœ‰æ•ˆé¡¹ç›®å¤ªå°‘ï¼Œæå‰é€€å‡º
            results = analysis_result.get("results", [])
            if not results or len(results) < 3:
                pbar.update(1)
                return None

            # === é˜¶æ®µ2ï¼šæ•°æ®å¤„ç†ï¼ˆå¯ä»¥å¹¶å‘ï¼‰===
            # ä½¿ç”¨æ•°æ®å¤„ç†ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°ï¼Œä½†å¯ä»¥å¤šä¸ªä»»åŠ¡åŒæ—¶å¤„ç†
            async with self.data_processing_semaphore:
                # 3. è®¡ç®—è¯„åˆ†ï¼ˆçº¯è®¡ç®—ï¼Œæ— APIè°ƒç”¨ï¼‰
                scores = WalletScorerV2.calculate_scores(analysis_result)

                # 4. è‡ªåŠ¨é»‘åå•è¿‡æ»¤ï¼ˆåƒåœ¾åœ°å€ï¼‰
                if scores["flags"].get("is_trash", False):
                    self.trash_manager.add(address)
                    pbar.update(1)
                    return None

                # 5. æå–è¯¦ç»†æŒ‡æ ‡ï¼ˆçº¯æ•°æ®å¤„ç†ï¼‰
                results = analysis_result["results"]
                dims = scores["dimensions"]
                profit_dim = dims["profit"]
                persistence_dim = dims["persistence"]
                authenticity_dim = dims["authenticity"]
                positioning = scores["positioning"]

                # 6. æå–æœ€ä½³å®šä½
                best_role = "æœªçŸ¥"
                best_role_score = 0
                if positioning:
                    best_role = max(positioning, key=positioning.get)
                    best_role_score = positioning[best_role]

                # 7. è®¡ç®—åŸºç¡€æŒ‡æ ‡
                wins = [r for r in results if r.get('is_win', False)]
                losses = [r for r in results if not r.get('is_win', False)]
                win_rate = len(wins) / len(results) if results else 0
                total_profit = profit_dim.get("total_profit", 0)
                max_roi = profit_dim.get("max_roi", 0)

                # 8. è®¡ç®—æœªç»“ç®—tokenç»Ÿè®¡ï¼ˆæ’é™¤ç²‰å°˜ï¼‰
                unsettled_tokens = [
                    r for r in results
                    if r.get('is_unsettled', False) and r.get('unrealized_sol', 0) >= DUST_THRESHOLD
                ]

                unsettled_count = len(unsettled_tokens)
                unsettled_profit = sum(r.get('unrealized_sol', 0) for r in unsettled_tokens)
                unsettled_hold_times = [r.get('hold_time', 0) for r in unsettled_tokens if r.get('hold_time', 0) > 0]
                unsettled_avg_hold_time = sum(unsettled_hold_times) / len(
                    unsettled_hold_times) if unsettled_hold_times else 0

                # è®¡ç®—æœªç»“ç®—tokençš„æ€»æˆæœ¬ï¼ˆç”¨äºè®¡ç®—ROIï¼‰
                # ä½¿ç”¨æœªç»“ç®—éƒ¨åˆ†çš„æˆæœ¬ï¼Œè€Œä¸æ˜¯æ€»ä¹°å…¥æˆæœ¬
                unsettled_cost = sum(r.get('unsettled_cost', 0) for r in unsettled_tokens)
                unsettled_roi = (unsettled_profit / unsettled_cost - 1) if unsettled_cost > 0 else 0

                # 9. è®¡ç®—å•å¸äºæŸè¶…è¿‡95%çš„æ•°é‡
                severe_loss_count = len([r for r in losses if r.get('roi', 0) <= -0.95])

                pbar.update(1)
                return {
                    "é’±åŒ…åœ°å€": address,
                    "ç»¼åˆè¯„åˆ†": scores["final_score"],
                    "æˆ˜åŠ›è¯„çº§": scores["tier"],
                    "æœ€ä½³å®šä½": best_role,
                    "å®šä½è¯„åˆ†": best_role_score,
                    "ç›ˆåˆ©åŠ›è¯„åˆ†": profit_dim.get("score", 0),
                    "æŒä¹…åŠ›è¯„åˆ†": persistence_dim.get("score", 0),
                    "çœŸå®æ€§è¯„åˆ†": authenticity_dim.get("score", 0),
                    "ç›ˆäºæ¯”": round(profit_dim.get("profit_factor", 0), 2),
                    "èƒœç‡": round(win_rate, 3),
                    "æ€»ç›ˆäº(SOL)": round(total_profit, 2),
                    "30å¤©ç›ˆåˆ©(SOL)": round(profit_dim.get("profit_30d", 0), 2),
                    "30å¤©ç›ˆåˆ©(%)": round(profit_dim.get("profit_pct_30d", 0), 2),
                    "7å¤©ç›ˆåˆ©(SOL)": round(profit_dim.get("profit_7d", 0), 2),
                    "7å¤©ç›ˆåˆ©(%)": round(profit_dim.get("profit_pct_7d", 0), 2),
                    "æœ€å¤§å•ç¬”ROI": f"{max_roi:.0%}",
                    "æœ€å¤§å•ç¬”äºæŸ": f"{profit_dim.get('max_single_loss', 0):.1%}",
                    "å¹³å‡æŒä»“(åˆ†é’Ÿ)": round(authenticity_dim.get("avg_hold_time", 0), 1),
                    "ç›ˆåˆ©æŒä»“(åˆ†é’Ÿ)": round(authenticity_dim.get("avg_win_hold_time", 0), 1),
                    "äºæŸæŒä»“(åˆ†é’Ÿ)": round(authenticity_dim.get("avg_loss_hold_time", 0), 1),
                    "ä»£å¸å¤šæ ·æ€§": authenticity_dim.get("unique_tokens", 0),
                    "30å¤©ä»£å¸æ•°": persistence_dim.get("tokens_30d", 0),
                    "30å¤©äº¤æ˜“æ•°": persistence_dim.get("tx_count_30d", 0),
                    "7å¤©ä»£å¸æ•°": persistence_dim.get("tokens_7d", 0),
                    "7å¤©äº¤æ˜“æ•°": persistence_dim.get("tx_count_7d", 0),
                    "é¡¹ç›®æ€»æ•°": len(results),
                    "æœªç»“ç®—tokenæ•°": unsettled_count,
                    "æœªç»“ç®—ç›ˆåˆ©(SOL)": round(unsettled_profit, 2),
                    "æœªç»“ç®—ROI": f"{unsettled_roi:.1%}",
                    "æœªç»“ç®—å¹³å‡æŒä»“(åˆ†é’Ÿ)": round(unsettled_avg_hold_time, 1),
                    "å•å¸äºæŸ>95%æ•°é‡": severe_loss_count,
                    "åˆ†ææ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M"),
                    "ğŸ›¡ï¸ ç¨³å¥ä¸­å†›": positioning.get("ğŸ›¡ï¸ ç¨³å¥ä¸­å†›", 0),
                    "âš”ï¸ åœŸç‹—çŒæ‰‹": positioning.get("âš”ï¸ åœŸç‹—çŒæ‰‹", 0),
                    "ğŸ’ é’»çŸ³ä¹‹æ‰‹": positioning.get("ğŸ’ é’»çŸ³ä¹‹æ‰‹", 0),
                    "ğŸš€ çŸ­çº¿é«˜æ‰‹": positioning.get("ğŸš€ çŸ­çº¿é«˜æ‰‹", 0),
                }

        except Exception as e:
            logger.error(f"åˆ†æé’±åŒ… {address[:8]}... æ—¶å‡ºé”™: {e}", exc_info=True)
            pbar.update(1)
            return None

    async def analyze_batch(
            self,
            addresses: List[str],
            max_txs: int = 5000,
            save_interval: int = 20,
            exporter: 'ReportExporterV2' = None
    ) -> List[Dict]:
        """
        æ‰¹é‡åˆ†æé’±åŒ…åˆ—è¡¨ï¼ˆç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼‰
        
        è®¾è®¡ï¼š
        - æ‰€æœ‰ä»»åŠ¡å¹¶å‘åˆ›å»ºï¼ˆç”Ÿäº§è€…ï¼‰
        - APIè°ƒç”¨å…è®¸Nä¸ªKeyå¹¶è¡Œï¼ˆN=keyæ•°é‡ï¼‰ï¼Œä½†åŒä¸€Keyå†…éƒ¨ä¸²è¡Œ
        - æ•°æ®å¤„ç†å¹¶å‘ï¼ˆé€šè¿‡data_processing_semaphoreï¼‰
        - æ¯å¤„ç†Nä¸ªé’±åŒ…è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡æŠ¥å‘Š
        
        Args:
            addresses: é’±åŒ…åœ°å€åˆ—è¡¨
            max_txs: æ¯ä¸ªé’±åŒ…æœ€å¤§äº¤æ˜“æ•°é‡ï¼ˆé»˜è®¤5000ï¼Œé™ä½ä»¥æå‡é€Ÿåº¦ï¼‰
            save_interval: æ¯å¤„ç†å¤šå°‘ä¸ªé’±åŒ…ä¿å­˜ä¸€æ¬¡æŠ¥å‘Šï¼ˆé»˜è®¤20ï¼‰
            exporter: æŠ¥å‘Šå¯¼å‡ºå™¨å®ä¾‹ï¼ˆç”¨äºå®šæœŸä¿å­˜ï¼‰
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        pbar = tqdm(total=len(addresses), desc="ğŸ“Š å®¡è®¡è¿›åº¦", unit="é’±åŒ…", colour="green")

        helius_key_count = len(self.helius_key_manager.key_list)
        jupiter_key_count = len(self.jupiter_key_manager.key_list)
        logger.info(
            f"å¼€å§‹åˆ†æ {len(addresses)} ä¸ªé’±åŒ…ï¼ˆHelius {helius_key_count}ä¸ªKeyå¹¶è¡Œï¼ŒJupiter {jupiter_key_count}ä¸ªKeyå¹¶è¡Œï¼Œæ•°æ®å¤„ç†å¹¶å‘{self.concurrent_limit}ï¼‰...")
        logger.info(f"æ¯æˆåŠŸåˆ†æ {save_interval} ä¸ªé’±åŒ…è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡æŠ¥å‘Šï¼ˆåªç»Ÿè®¡æˆåŠŸçš„ï¼‰")

        # å…±äº«çš„ç»“æœåˆ—è¡¨å’Œè®¡æ•°å™¨ï¼ˆç”¨äºå®šæœŸä¿å­˜ï¼‰
        all_results: List[Dict] = []
        completed_count = 0  # æˆåŠŸåˆ†æçš„é’±åŒ…æ•°ï¼ˆåªç»Ÿè®¡æˆåŠŸçš„ï¼‰
        results_lock = asyncio.Lock()
        save_lock = asyncio.Lock()  # ä¿å­˜æ“ä½œçš„é”ï¼Œç¡®ä¿åŒæ—¶åªæœ‰ä¸€ä¸ªä¿å­˜ä»»åŠ¡
        save_tasks: List[asyncio.Task] = []  # æ‰€æœ‰ä¿å­˜ä»»åŠ¡åˆ—è¡¨

        # ç¡®ä¿ exporter åœ¨é—­åŒ…ä¸­å¯ç”¨
        if exporter is None:
            logger.warning("âš ï¸ exporter ä¸º Noneï¼Œä¸­é—´æŠ¥å‘Šä¿å­˜åŠŸèƒ½å°†è¢«ç¦ç”¨")

        async def save_report_async(results_to_save: List[Dict], count: int):
            """
            å¼‚æ­¥ä¿å­˜æŠ¥å‘Šï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            
            Args:
                results_to_save: è¦ä¿å­˜çš„ç»“æœåˆ—è¡¨ï¼ˆå¤åˆ¶ä¸€ä»½é¿å…å¹¶å‘ä¿®æ”¹ï¼‰
                count: å½“å‰å®Œæˆæ•°é‡
            """
            async with save_lock:
                try:
                    logger.info(f"ğŸ”„ å¼€å§‹ä¿å­˜ä¸­é—´æŠ¥å‘Š ({count} ä¸ªé’±åŒ…ï¼Œç»“æœæ•°: {len(results_to_save)})...")

                    # æ£€æŸ¥ exporter æ˜¯å¦å­˜åœ¨
                    if exporter is None:
                        logger.error(f"âŒ exporter ä¸º Noneï¼Œæ— æ³•ä¿å­˜ ({count} ä¸ªé’±åŒ…)")
                        return

                    # ç›´æ¥è°ƒç”¨ export æ–¹æ³•ï¼ˆä¸ä½¿ç”¨ run_in_executorï¼Œé¿å…é—®é¢˜ï¼‰
                    # å› ä¸º pandas æ“ä½œå¾ˆå¿«ï¼Œä¸éœ€è¦æ”¾åˆ°çº¿ç¨‹æ± 
                    try:
                        temp_file = exporter.export(
                            results_to_save.copy(),  # å¤åˆ¶ä¸€ä»½é¿å…å¹¶å‘ä¿®æ”¹
                            RESULTS_DIR,
                            True  # is_temp=True
                        )
                        if temp_file:
                            abs_path = os.path.abspath(temp_file)
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                            if os.path.exists(temp_file):
                                file_size = os.path.getsize(temp_file)
                                logger.info(f"âœ… å·²ä¿å­˜ä¸­é—´æŠ¥å‘Š: {abs_path} ({count} ä¸ªé’±åŒ…ï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚)")
                            else:
                                logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {abs_path}")
                        else:
                            logger.warning(f"âš ï¸ ä¿å­˜ä¸­é—´æŠ¥å‘Šè¿”å› None ({count} ä¸ªé’±åŒ…)")
                    except Exception as export_error:
                        logger.error(f"âŒ è°ƒç”¨ exporter.export å¤±è´¥ ({count} ä¸ªé’±åŒ…): {export_error}", exc_info=True)
                        raise
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜ä¸­é—´æŠ¥å‘Šå¤±è´¥ ({count} ä¸ªé’±åŒ…): {e}", exc_info=True)

        async def analyze_task(session, addr, index):
            """
            å•ä¸ªé’±åŒ…åˆ†æä»»åŠ¡ï¼ˆç”Ÿäº§è€…ï¼‰
            å†…éƒ¨ä¼šé€šè¿‡é”æ§åˆ¶APIè°ƒç”¨ï¼ˆæ¯ä¸ªKeyç‹¬ç«‹é”ï¼‰ï¼Œæ•°æ®å¤„ç†å¹¶å‘
            """
            nonlocal completed_count, save_tasks
            try:
                result = await self.analyze_one_wallet(session, addr, pbar, max_txs)

                if result is not None:
                    should_save = False
                    current_count = 0
                    async with results_lock:
                        all_results.append(result)
                        completed_count += 1  # åªç»Ÿè®¡æˆåŠŸçš„
                        current_count = completed_count  # ä¿å­˜å½“å‰å€¼ï¼Œç”¨äºæ—¥å¿—

                        # æ¯æˆåŠŸåˆ†æNä¸ªé’±åŒ…ä¿å­˜ä¸€æ¬¡æŠ¥å‘Šï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
                        if completed_count % save_interval == 0:
                            if exporter:
                                should_save = True
                                logger.info(
                                    f"ğŸ“ è§¦å‘ä¿å­˜ä»»åŠ¡: æˆåŠŸåˆ†æ {completed_count} ä¸ªé’±åŒ…ï¼Œç»“æœæ•°: {len(all_results)}")
                            else:
                                logger.warning(
                                    f"âš ï¸ exporter ä¸º Noneï¼Œæ— æ³•ä¿å­˜ä¸­é—´æŠ¥å‘Š (æˆåŠŸåˆ†æ {completed_count} ä¸ªé’±åŒ…)")

                        # # æ¯æˆåŠŸåˆ†æ10ä¸ªé’±åŒ…è¾“å‡ºä¸€æ¬¡æ—¥å¿—ï¼ˆæ›´é¢‘ç¹ï¼Œä¾¿äºè°ƒè¯•ï¼‰
                        # if completed_count % 10 == 0:
                        #     logger.info(f"è¿›åº¦: æˆåŠŸåˆ†æ {completed_count} ä¸ªé’±åŒ… ({100*completed_count/len(addresses):.1f}%)")

                        # æ¯æˆåŠŸåˆ†æ50ä¸ªé’±åŒ…è¾“å‡ºä¸€æ¬¡è¯¦ç»†æ—¥å¿—
                        if completed_count % 50 == 0:
                            logger.info(f"è¯¦ç»†è¿›åº¦: æˆåŠŸåˆ†æ {completed_count} ä¸ªé’±åŒ…ï¼Œç»“æœæ•°: {len(all_results)}")

                            # æ¸…ç†ä»·æ ¼ç¼“å­˜ï¼ˆæ¯50ä¸ªé’±åŒ…æ¸…ç†ä¸€æ¬¡ï¼‰
                            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è®¿é—®analyzerçš„price_fetcherï¼Œä½†å®ƒæ˜¯æ¯ä¸ªé’±åŒ…ç‹¬ç«‹çš„
                            # æ‰€ä»¥ç¼“å­˜æ¸…ç†åœ¨PriceFetcherå†…éƒ¨è‡ªåŠ¨è¿›è¡Œ

                    # å¼‚æ­¥ä¿å­˜ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
                    if should_save:
                        logger.info(f"ğŸ”„ åˆ›å»ºä¿å­˜ä»»åŠ¡: æˆåŠŸåˆ†æ {current_count} ä¸ªé’±åŒ…ï¼Œç»“æœæ•°: {len(all_results)}")
                        # åˆ›å»ºå¼‚æ­¥ä¿å­˜ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
                        try:
                            task = asyncio.create_task(
                                save_report_async(all_results.copy(), current_count)
                            )
                            save_tasks.append(task)
                            logger.info(f"âœ… ä¿å­˜ä»»åŠ¡å·²åˆ›å»ºï¼Œå½“å‰å…±æœ‰ {len(save_tasks)} ä¸ªä¿å­˜ä»»åŠ¡")
                        except Exception as task_error:
                            logger.error(f"âŒ åˆ›å»ºä¿å­˜ä»»åŠ¡å¤±è´¥: {task_error}", exc_info=True)

                return result
            except Exception as e:
                logger.error(f"å¤„ç†é’±åŒ… {addr[:8]}... æ—¶å‡ºé”™: {e}")
                pbar.update(1)
                return None

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡å¹¶å‘æ‰§è¡Œï¼ˆç”Ÿäº§è€…æ¨¡å¼ï¼‰
        # APIè°ƒç”¨ä¼šåœ¨å†…éƒ¨é€šè¿‡æ¯ä¸ªKeyçš„ç‹¬ç«‹é”æ§åˆ¶ï¼ˆå…è®¸Nä¸ªKeyå¹¶è¡Œï¼ŒN=keyæ•°é‡ï¼‰
        # æ•°æ®å¤„ç†å¯ä»¥é€šè¿‡data_processing_semaphoreå¹¶å‘
        async with aiohttp.ClientSession() as session:
            tasks = [analyze_task(session, addr, i) for i, addr in enumerate(addresses)]
            raw_results = await asyncio.gather(*tasks, return_exceptions=True)
            # è¿‡æ»¤æ‰å¼‚å¸¸å’ŒNoneï¼ˆç»“æœå·²ç»åœ¨analyze_taskä¸­æ·»åŠ åˆ°all_resultsï¼‰
            exception_count = 0
            for r in raw_results:
                if isinstance(r, Exception):
                    exception_count += 1
                    if exception_count <= 5:  # åªè®°å½•å‰5ä¸ªå¼‚å¸¸
                        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {r}")
            if exception_count > 5:
                logger.warning(f"è¿˜æœ‰ {exception_count - 5} ä¸ªå¼‚å¸¸æœªæ˜¾ç¤º")

        # ç­‰å¾…æ‰€æœ‰ä¿å­˜ä»»åŠ¡å®Œæˆ
        if save_tasks:
            logger.info(f"ç­‰å¾… {len(save_tasks)} ä¸ªä¿å­˜ä»»åŠ¡å®Œæˆ...")
            await asyncio.gather(*save_tasks, return_exceptions=True)
            logger.info("æ‰€æœ‰ä¿å­˜ä»»åŠ¡å·²å®Œæˆ")

        pbar.close()
        return all_results


class ReportExporterV2:
    """
    æŠ¥å‘Šå¯¼å‡ºå™¨ V2ï¼šè´Ÿè´£å¯¼å‡ºåˆ†æç»“æœåˆ° Excelï¼ˆåŒ…å«è¯¦ç»†è¯„åˆ†ï¼‰
    """

    @staticmethod
    def export(results: List[Dict], output_dir: str = RESULTS_DIR, is_temp: bool = False) -> Optional[str]:
        """
        å¯¼å‡ºåˆ†æç»“æœåˆ° Excel
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            is_temp: æ˜¯å¦ä¸ºä¸´æ—¶æ–‡ä»¶ï¼ˆTrueåˆ™è¦†ç›–ä¸´æ—¶æ–‡ä»¶ï¼ŒFalseåˆ™åˆ›å»ºæ–°æ–‡ä»¶ï¼‰
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
        """
        if not results:
            logger.warning(f"æ²¡æœ‰ç»“æœå¯å¯¼å‡º (resultsä¸ºç©ºï¼Œé•¿åº¦: {len(results) if results else 0})")
            return None

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        try:
            # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
            df = pd.DataFrame(results).sort_values(by="ç»¼åˆè¯„åˆ†", ascending=False)

            # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œè®©é‡è¦ä¿¡æ¯åœ¨å‰é¢
            important_cols = [
                "é’±åŒ…åœ°å€", "ç»¼åˆè¯„åˆ†", "æˆ˜åŠ›è¯„çº§", "æœ€ä½³å®šä½", "å®šä½è¯„åˆ†",
                "ç›ˆåˆ©åŠ›è¯„åˆ†", "æŒä¹…åŠ›è¯„åˆ†", "çœŸå®æ€§è¯„åˆ†",
                "ç›ˆäºæ¯”", "èƒœç‡", "æ€»ç›ˆäº(SOL)", "30å¤©ç›ˆåˆ©(SOL)", "30å¤©ç›ˆåˆ©(%)",
                "7å¤©ç›ˆåˆ©(SOL)", "7å¤©ç›ˆåˆ©(%)", "æœ€å¤§å•ç¬”ROI", "æœ€å¤§å•ç¬”äºæŸ",
                "å¹³å‡æŒä»“(åˆ†é’Ÿ)", "ç›ˆåˆ©æŒä»“(åˆ†é’Ÿ)", "äºæŸæŒä»“(åˆ†é’Ÿ)",
                "ä»£å¸å¤šæ ·æ€§", "30å¤©ä»£å¸æ•°", "30å¤©äº¤æ˜“æ•°", "7å¤©ä»£å¸æ•°", "7å¤©äº¤æ˜“æ•°",
                "é¡¹ç›®æ€»æ•°", "æœªç»“ç®—tokenæ•°", "æœªç»“ç®—ç›ˆåˆ©(SOL)", "æœªç»“ç®—ROI", "æœªç»“ç®—å¹³å‡æŒä»“(åˆ†é’Ÿ)",
                "å•å¸äºæŸ>95%æ•°é‡",
                "ğŸ›¡ï¸ ç¨³å¥ä¸­å†›", "âš”ï¸ åœŸç‹—çŒæ‰‹", "ğŸ’ é’»çŸ³ä¹‹æ‰‹", "ğŸš€ çŸ­çº¿é«˜æ‰‹",
                "åˆ†ææ—¶é—´"
            ]

            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
            available_cols = [col for col in important_cols if col in df.columns]
            remaining_cols = [col for col in df.columns if col not in available_cols]
            df = df[available_cols + remaining_cols]

            if is_temp:
                # ä¸´æ—¶æ–‡ä»¶ï¼šè¦†ç›–åŒä¸€ä¸ªæ–‡ä»¶
                output_file = os.path.join(output_dir, "wallet_ranking_v2_temp.xlsx")
            else:
                # æœ€ç»ˆæ–‡ä»¶ï¼šåˆ›å»ºæ–°æ–‡ä»¶
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = os.path.join(output_dir, f"wallet_ranking_v2_{timestamp}.xlsx")

            df.to_excel(output_file, index=False, engine='openpyxl')
            abs_path = os.path.abspath(output_file)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„åˆ›å»ºæˆåŠŸ
            if os.path.exists(output_file):
                file_size = os.path.getsize(output_file)
                logger.info(f"âœ… å¯¼å‡ºæˆåŠŸ: {abs_path} ({len(results)} æ¡è®°å½•ï¼Œæ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚)")
            else:
                logger.error(f"âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {abs_path}")
                return None

            return output_file
        except Exception as e:
            logger.error(f"å¯¼å‡ºå¤±è´¥: {e}")
            return None


async def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡åˆ†æå…¥å£"""
    # æ£€æŸ¥ API Key é…ç½®
    helius_keys = [k for k in HELIUS_KEY_LIST if k and k.strip()]
    jupiter_keys = [k for k in JUPITER_KEY_LIST if k and k.strip()]

    if not helius_keys:
        print("âŒ é”™è¯¯ï¼šHELIUS_KEY_LIST æœªé…ç½®ï¼Œè¯·åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ä½ çš„ Helius API Keys")
        return

    if not jupiter_keys:
        print("âŒ é”™è¯¯ï¼šJUPITER_KEY_LIST æœªé…ç½®ï¼Œè¯·åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ä½ çš„ Jupiter API Keys")
        return

    # åˆå§‹åŒ– API Key ç®¡ç†å™¨
    helius_key_manager = APIKeyManager(helius_keys, "Helius")
    jupiter_key_manager = APIKeyManager(jupiter_keys, "Jupiter")

    logger.info(f"å·²é…ç½® {len(helius_keys)} ä¸ª Helius API Keys")
    logger.info(f"å·²é…ç½® {len(jupiter_keys)} ä¸ª Jupiter API Keys")

    # åˆå§‹åŒ–ç»„ä»¶
    analyzer = WalletAnalyzerV2()  # ä¸éœ€è¦ä¼ å…¥keyï¼Œå› ä¸ºä¼šåœ¨è°ƒç”¨æ—¶åŠ¨æ€è·å–
    trash_manager = TrashListManager()
    batch_analyzer = BatchAnalyzerV2(
        analyzer,
        trash_manager,
        helius_key_manager,
        jupiter_key_manager,
        CONCURRENT_LIMIT
    )
    exporter = ReportExporterV2()

    # åŠ è½½é’±åŒ…åˆ—è¡¨å’Œé»‘åå•
    trash_set = trash_manager.load()
    all_addresses = WalletListLoader.load()

    if not all_addresses:
        print("âŒ æœªæ‰¾åˆ°é’±åŒ…åœ°å€åˆ—è¡¨")
        return

    # è¿‡æ»¤é»‘åå•
    addresses = [a for a in all_addresses if not trash_manager.contains(a)]
    skip_count = len(all_addresses) - len(addresses)

    if not addresses:
        print(f"ğŸš« åº“ä¸­æ‰€æœ‰åœ°å€éƒ½åœ¨é»‘åå•å†…ï¼Œæˆ–æ²¡æœ‰æ–°åœ°å€ã€‚")
        return

    print(f"ğŸš€ å¯åŠ¨æ‰¹é‡åˆ†æ V2 (è¶…ä¸¥æ ¼ç‰ˆ) | ä»»åŠ¡æ•°: {len(addresses)} (è·³è¿‡é»‘åå•: {skip_count})")

    # æ‰§è¡Œæ‰¹é‡åˆ†æï¼ˆæ¯20ä¸ªé’±åŒ…è‡ªåŠ¨ä¿å­˜ä¸€æ¬¡ï¼‰
    results = await batch_analyzer.analyze_batch(addresses, save_interval=20, exporter=exporter)

    # å¯¼å‡ºæœ€ç»ˆç»“æœï¼ˆè¦†ç›–ä¸´æ—¶æ–‡ä»¶æˆ–åˆ›å»ºæ–°æ–‡ä»¶ï¼‰
    if results:
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        temp_file = os.path.join(RESULTS_DIR, "wallet_ranking_v2_temp.xlsx")
        if os.path.exists(temp_file):
            try:
                os.remove(temp_file)
                logger.debug(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file}")
            except Exception as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        # å¯¼å‡ºæœ€ç»ˆæŠ¥å‘Š
        output_file = exporter.export(results, is_temp=False)
        if output_file:
            print(f"\nâœ… å¯¼å‡ºæˆåŠŸ: {output_file}")
            print(f"ğŸ“Š å…±åˆ†æ {len(results)} ä¸ªé’±åŒ…ï¼Œå·²æŒ‰ç»¼åˆè¯„åˆ†æ’åº")

            # æ˜¾ç¤ºå‰5å
            if len(results) > 0:
                print("\nğŸ† Top 5 é’±åŒ…:")
                for i, r in enumerate(results[:5], 1):
                    print(
                        f"  {i}. {r['é’±åŒ…åœ°å€'][:8]}... | è¯„åˆ†: {r['ç»¼åˆè¯„åˆ†']} | è¯„çº§: {r['æˆ˜åŠ›è¯„çº§']} | å®šä½: {r['æœ€ä½³å®šä½']} | 30å¤©ç›ˆåˆ©: {r['30å¤©ç›ˆåˆ©(SOL)']:+.2f} SOL")
        else:
            print("\nâš ï¸ å¯¼å‡ºå¤±è´¥")
    else:
        print("\nğŸ åˆ†æç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥æŠ¥é”™æˆ–åœ°å€åˆ—è¡¨ã€‚")

    # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„é’±åŒ…åœ°å€ï¼ˆä»åˆ†æç»“æœå’ŒåŸå§‹åˆ—è¡¨ä¸­æå–ï¼‰
    valid_addresses = set()

    # 1. ä»åˆ†æç»“æœä¸­æå–ï¼ˆè¿™äº›æ˜¯æˆåŠŸåˆ†æçš„é’±åŒ…ï¼‰
    if results:
        for r in results:
            addr = r.get('é’±åŒ…åœ°å€', '').strip()
            if addr and is_valid_solana_address(addr):
                valid_addresses.add(addr)

    # 2. ä»åŸå§‹åˆ—è¡¨ä¸­æå–ï¼ˆåŒ…æ‹¬æœªåˆ†æä½†æ ¼å¼æ­£ç¡®çš„åœ°å€ï¼‰
    for addr in all_addresses:
        addr = addr.strip()
        if addr and is_valid_solana_address(addr):
            valid_addresses.add(addr)

    # 3. ä¿å­˜æœ‰æ•ˆçš„é’±åŒ…åœ°å€å›æ–‡ä»¶
    if valid_addresses:
        saved = WalletListSaver.save_valid_addresses(list(valid_addresses), WALLETS_FILE)
        if saved:
            print(f"\nâœ… å·²è¿‡æ»¤å¹¶ä¿å­˜ {len(valid_addresses)} ä¸ªæœ‰æ•ˆé’±åŒ…åœ°å€åˆ° {WALLETS_FILE}")
        else:
            print(f"\nâš ï¸ ä¿å­˜é’±åŒ…åœ°å€å¤±è´¥")
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„é’±åŒ…åœ°å€")


if __name__ == "__main__":
    asyncio.run(main())
